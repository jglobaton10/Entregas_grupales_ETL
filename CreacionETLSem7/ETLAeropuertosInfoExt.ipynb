{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40a703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import monotonically_increasing_id as mid\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f13250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "host='localhost'\n",
    "user='root'\n",
    "passwd=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3761fefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=host,\n",
    "  user=user,\n",
    "  passwd=passwd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5869ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da274e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#se crea la base de dato usando comandos de sql en pyspark, en este momento se encuentra como comentario\n",
    "#query = 'CREATE DATABASE proyectoaeropuertosinfoext'\n",
    "#mycursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2400d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Application',)\n",
      "('Sales',)\n",
      "('WWImportersDWH',)\n",
      "('WWImportersTransactional',)\n",
      "('Warehouse',)\n",
      "('information_schema',)\n",
      "('mysql',)\n",
      "('performance_schema',)\n",
      "('proyectoaeropuertosV2',)\n",
      "('proyectoaeropuertosconhistoria',)\n",
      "('proyectoaeropuertosinfoext',)\n",
      "('sys',)\n"
     ]
    }
   ],
   "source": [
    "#Verificar que la base de datos existe\n",
    "databases = (\"show databases\")\n",
    "mycursor.execute(databases)\n",
    "for i in mycursor:\n",
    "     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27fd2600",
   "metadata": {},
   "outputs": [],
   "source": [
    "definedb=\"USE proyectoaeropuertosinfoext\"\n",
    "mycursor.execute(definedb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "89b98da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "creacion_tablas='\\\n",
    "CREATE TABLE IF NOT EXISTS DimFecha\\\n",
    "(\\\n",
    "    IDFecha INT NOT NULL,\\\n",
    "    Año CHARACTER(4),\\\n",
    "    Mes CHARACTER(2),\\\n",
    "    PRIMARY KEY(IDFecha)\\\n",
    ");\\\n",
    "\\\n",
    "CREATE TABLE IF NOT EXISTS DimTipo_Equipo\\\n",
    "(\\\n",
    "    IDEquipo INT NOT NULL,\\\n",
    "    NombreEquipo CHARACTER(4),\\\n",
    "    PRIMARY KEY(IDEquipo)\\\n",
    ");\\\n",
    "\\\n",
    "CREATE TABLE IF NOT EXISTS DimTipoVuelo\\\n",
    "(\\\n",
    "    IDTipoVuelo INT NOT NULL,\\\n",
    "    CodigoVuelo CHARACTER(1),\\\n",
    "    TipoVuelo CHARACTER(10),\\\n",
    "    PRIMARY KEY(IDTipoVuelo)\\\n",
    ");\\\n",
    "\\\n",
    "CREATE TABLE IF NOT EXISTS DimTipo_Trafico\\\n",
    "(\\\n",
    "    IDTipoTrafico INT NOT NULL,\\\n",
    "    Codigo_Trafico CHARACTER(1),\\\n",
    "    Descripcion CHARACTER(10),\\\n",
    "    PRIMARY KEY(IDTipoTrafico)\\\n",
    ");\\\n",
    "\\\n",
    "CREATE TABLE IF NOT EXISTS DimEmpresaTransportadora\\\n",
    "(\\\n",
    "    IDEmpresa INT NOT NULL,\\\n",
    "    NombreEmpresa CHARACTER(50),\\\n",
    "    PRIMARY KEY(IDEmpresa)\\\n",
    ");\\\n",
    "\\\n",
    "CREATE TABLE IF NOT EXISTS FactVuelos\\\n",
    "(\\\n",
    "    ID INT NOT NULL,\\\n",
    "    IDFecha INT,\\\n",
    "    IDEquipo INT,\\\n",
    "    IDAeropuertoOrigen INT,\\\n",
    "    IDAeropuertoDestino INT,\\\n",
    "    IDTipoVuelo INT,\\\n",
    "    IDTipoTrafico INT,\\\n",
    "    IDEmpresa INT,\\\n",
    "    Vuelos INT,\\\n",
    "    Pasajeros INT,\\\n",
    "    CargaBordo INT,\\\n",
    "    TotalSillas INT,\\\n",
    "    TotalCarga INT,\\\n",
    "    PRIMARY KEY(ID)\\\n",
    ");\\\n",
    "\\\n",
    "CREATE TABLE IF NOT EXISTS DimAeropuertoHistoria\\\n",
    "(\\\n",
    "    IDAeropuerto INT NOT NULL,\\\n",
    "    Sigla CHARACTER(3),\\\n",
    "    IATA CHARACTER(3),\\\n",
    "    NombreAeropuerto CHARACTER(50),\\\n",
    "    Municipio CHARACTER(50),\\\n",
    "    Departamento CHARACTER(50),\\\n",
    "    Categoria CHARACTER(50),\\\n",
    "    Latitud DOUBLE,\\\n",
    "    Longitud DOUBLE,\\\n",
    "    idMunicipio INT,\\\n",
    "    Propietario CHARACTER(50),\\\n",
    "    Explotador CHARACTER(50),\\\n",
    "    LongitudPista INT,\\\n",
    "    AnchoPista INT,\\\n",
    "    PBMO INT,\\\n",
    "    Elevacion INT,\\\n",
    "    Resolucion INT,\\\n",
    "    Clase CHARACTER(50),\\\n",
    "    Tipo CHARACTER(50),\\\n",
    "    GCD_Municipio CHARACTER(50),\\\n",
    "    GCD_Departamento CHARACTER(50),\\\n",
    "    FechaInicioVigencia DATE,\\\n",
    "    FechaFinVigencia DATE,\\\n",
    "    VersionDelRegistro CHARACTER(1),\\\n",
    "    Anio INT,\\\n",
    "    IDPIB INT,\\ \n",
    "    PRIMARY KEY(IDAeropuerto)\\\n",
    ");\\\n",
    "\\\n",
    "CREATE TABLE IF NOT EXISTS DimInformacionPIB\\\n",
    "(\\\n",
    "    IDPIB INT NOT NULL,\\\n",
    "    PIB INT,\\\n",
    "    FechaInicioVigencia DATE,\\\n",
    "    FechaFinVigencia DATE,\\\n",
    "    VersionRegistro CHARACTER(1),\\\n",
    "    PRIMARY KEY(IDPIB)\\\n",
    ");\\\n",
    "'\n",
    "mycursor.execute(creacion_tablas)\n",
    "\n",
    "# reestablecer_historia='DROP TABLE proyectoaeropuertosinfoext.DimInformacionPIB;'\n",
    "# mycursor.execute(reestablecer_historia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e8e70a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('DimAeropuertoHistoria',)\n",
      "('DimEmpresaTransportadora',)\n",
      "('DimFecha',)\n",
      "('DimInformacionPIB',)\n",
      "('DimTipoVuelo',)\n",
      "('DimTipo_Equipo',)\n",
      "('DimTipo_Trafico',)\n",
      "('FactVuelos',)\n"
     ]
    }
   ],
   "source": [
    "# se muestran las tablas\n",
    "showtables=\"SHOW TABLES FROM proyectoaeropuertosinfoext\"\n",
    "mycursor.execute(showtables)\n",
    "\n",
    "for table_name in mycursor:\n",
    "    print(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e79882f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_multidimensional_connection_string = 'jdbc:mysql://localhost:3306/proyectoaeropuertosinfoext'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfd65643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars /usr/share/java/mariadb-java-client-2.5.3.jar pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fe13df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_context = SparkContext()\n",
    "sql_context = SQLContext(spark_context)\n",
    "spark = sql_context.sparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e02414b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvuelosnew = spark.read.format(\"csv\").load(\"vuelos.csv\",format=\"csv\",sep=\",\",\n",
    "                                         inferSchema='true',header='true')\n",
    "dfaeropuertosconhistoria =spark.read.format(\"csv\").load(\"aeropuertos.csv\",format=\"csv\",sep=\",\",\n",
    "                                         inferSchema='true',header='true')\n",
    "dfPIB=spark.read.format(\"csv\").load(\"InformacionPIB.csv\",format=\"csv\",sep=\",\",\n",
    "                                         inferSchema='true',header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08155ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+-------+-----------+----------+-------+-----------+------+------+--------------+---------+-----------+\n",
      "| ano|mes|origen|destino|tipo_equipo|tipo_vuelo|trafico|    empresa|vuelos|sillas|carga_ofrecida|pasajeros|carga_bordo|\n",
      "+----+---+------+-------+-----------+----------+-------+-----------+------+------+--------------+---------+-----------+\n",
      "|2010|  1|   7NS|    VVC|       B190|         T|      N|SEARCA S.A.|     3|    48|           460|       48|        460|\n",
      "|2010|  1|   7NT|    BOG|       B190|         T|      N|SEARCA S.A.|     6|    65|           521|       65|        521|\n",
      "|2010|  1|   7NT|    VVC|       B190|         T|      N|SEARCA S.A.|     1|    14|             0|       14|          0|\n",
      "|2010|  1|   9AI|    EYP|       C172|         T|      N| AERO APOYO|     2|     3|             0|        3|          0|\n",
      "|2010|  1|   9AI|    EYP|       C182|         T|      N| AERO APOYO|     2|     5|            30|        5|         30|\n",
      "+----+---+------+-------+-----------+----------+-------+-----------+------+------+--------------+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfvuelosnew.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c08f384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+------------+-------------+------------+---------+-------+--------+--------------------+--------------+--------------+-----------+----+---------+----------+------------------+--------------+-----+----------+--------------------+----------------+-------------+----+\n",
      "|sigla|           iata|      nombre|    municipio|departamento|categoria|latitud|longitud|         propietario|    explotador|longitud_pista|ancho_pista|pbmo|elevacion|resolucion|fecha_construccion|fecha_vigencia|clase|      tipo|numero_vuelos_origen|gcd_departamento|gcd_municipio| Ano|\n",
      "+-----+---------------+------------+-------------+------------+---------+-------+--------+--------------------+--------------+--------------+-----------+----+---------+----------+------------------+--------------+-----+----------+--------------------+----------------+-------------+----+\n",
      "|  7FO|no-especificado|     LA ISLA|Puerto Gaitán|        Meta|Aeródromo| 4.4211|-71.6271|LA ISLA Y EL ROSA...| LA CEIBA S.A.|          1079|         19|3000|      538| 1,325,000|        06/05/2015|    06/11/2018|   1A|Fumigación|                   2|              50|        50568|2015|\n",
      "|  7FO|no-especificado|     LA ISLA|Puerto Gaitán|        Meta|Aeródromo| 4.4211|-71.6271|LA ISLA Y EL ROSA...| LA CEIBA S.A.|          1321|         38|3000|      538| 1,325,000|        06/05/2015|    06/11/2018|   1A|Fumigación|                   2|              50|        50568|2016|\n",
      "|  7FU|no-especificado|LA ESCONDIDA|Puerto Gaitán|        Meta|Aeródromo| 4.6108|-71.1935|PALMAS SICARARE S...|COSARGO S.A.S.|          2141|         17|5000|      564| 1,843,000|        04/26/2013|    05/07/2016|   1A| Aerocivil|                  24|              50|        50568|2014|\n",
      "|  7FU|no-especificado|LA ESCONDIDA|Puerto Gaitán|        Meta|Aeródromo| 4.6108|-71.1935|PALMAS SICARARE S...|COSARGO S.A.S.|          3853|          5|5000|      564| 1,843,000|        04/26/2013|    05/07/2016|   1A| Aerocivil|                  24|              50|        50568|2015|\n",
      "|  7FU|no-especificado|LA ESCONDIDA|Puerto Gaitán|        Meta|Aeródromo| 4.6108|-71.1935|PALMAS SICARARE S...|COSARGO S.A.S.|          6667|          5|5000|      564| 1,843,000|        04/26/2013|    05/07/2016|   1A|   Público|                  12|              50|        50568|2016|\n",
      "+-----+---------------+------------+-------------+------------+---------+-------+--------+--------------------+--------------+--------------+-----------+----+---------+----------+------------------+--------------+-----+----------+--------------------+----------------+-------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfaeropuertosconhistoria.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06424394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+-----+-----+-----+-----+-----+-----+-----+\n",
      "|Codigo|DEPARTAMENTOS| 2014| 2015| 2016| 2017| 2018| 2019| 2020|\n",
      "+------+-------------+-----+-----+-----+-----+-----+-----+-----+\n",
      "|    91|     Amazonas|  157|  178|  199|  213|  224|  238|  174|\n",
      "|     5|    Antioquia|16705|18734|21462|22797|24232|26405|23337|\n",
      "|    81|       Arauca|  411|  457|  517|  514|  542|  580|  519|\n",
      "|     8|    Atlántico| 6041| 7001| 7899| 8294| 8886| 9652| 8806|\n",
      "|    11|  BOGOTÁ D.C.|35338|39760|44469|47413|50966|55824|48915|\n",
      "+------+-------------+-----+-----+-----+-----+-----+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfPIB.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93d0c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sequence, to_date, explode, col,when,lit,expr,substring,regexp_replace\n",
    "from pyspark.sql import functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "594a5959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-------+\n",
      "|Anio|Mes|IDFecha|\n",
      "+----+---+-------+\n",
      "|2010|  1|      0|\n",
      "|2010|  2|      1|\n",
      "|2010|  3|      2|\n",
      "|2010|  4|      3|\n",
      "|2010|  5|      4|\n",
      "+----+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creacion tabla DimFechaMes\n",
    "df_fechames=dfvuelosnew.selectExpr('ano as Anio', 'mes as Mes')\n",
    "df_fechames=df_fechames.dropDuplicates()\n",
    "df_fechames=df_fechames.sort(col(\"Anio\"),col('Mes'))\n",
    "df_fechames = df_fechames.coalesce(1).withColumn(\"IDFecha\", mid())\n",
    "df_fechames.toPandas().to_csv('ModelExt/DimFechaMes.csv')\n",
    "df_fechames.select('*').write.format('jdbc') \\\n",
    "          .mode('overwrite') \\\n",
    "          .option('url', db_multidimensional_connection_string) \\\n",
    "          .option('dbtable', 'DimFechaMes') \\\n",
    "          .option('user', user) \\\n",
    "          .option('password', passwd) \\\n",
    "          .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "          .save()\n",
    "df_fechames.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "09f6b806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----------+\n",
      "|CodigoVuelo|  TipoVuelo|IDTipoVuelo|\n",
      "+-----------+-----------+-----------+\n",
      "|          A|Adicionales|          0|\n",
      "|          C|    Charter|          1|\n",
      "|          R|    Regular|          2|\n",
      "|          T|       Taxi|          3|\n",
      "|        nan|        nan|          4|\n",
      "+-----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creacion tabla DimTipoVuelo\n",
    "df_tipo_vuelo=dfvuelosnew.selectExpr('tipo_vuelo as CodigoVuelo')\n",
    "df_tipo_vuelo=df_tipo_vuelo.dropDuplicates()\n",
    "df_tipo_vuelo=df_tipo_vuelo.withColumn(\"TipoVuelo\", \\\n",
    "   when((df_tipo_vuelo.CodigoVuelo ==\"A\"), \"Adicionales\") \\\n",
    "   .when((df_tipo_vuelo.CodigoVuelo ==\"C\"),\"Charter\") \\\n",
    "   .when((df_tipo_vuelo.CodigoVuelo ==\"R\"),\"Regular\") \\\n",
    "   .when((df_tipo_vuelo.CodigoVuelo ==\"T\"),\"Taxi\") \\\n",
    "   .otherwise(\"nan\") \\\n",
    "  )\n",
    "nandf = spark.createDataFrame([('nan','nan')], df_tipo_vuelo.columns)\n",
    "df_tipo_vuelo = df_tipo_vuelo.union(nandf)\n",
    "df_tipo_vuelo=df_tipo_vuelo.sort(col(\"CodigoVuelo\"))\n",
    "df_tipo_vuelo = df_tipo_vuelo.coalesce(1).withColumn(\"IDTipoVuelo\", mid())\n",
    "df_tipo_vuelo.toPandas().to_csv('ModelExt/DimTipoVuelo.csv')\n",
    "df_tipo_vuelo.select('*').write.format('jdbc') \\\n",
    "          .mode('overwrite') \\\n",
    "          .option('url', db_multidimensional_connection_string) \\\n",
    "          .option('dbtable', 'DimTipoVuelo') \\\n",
    "          .option('user', user) \\\n",
    "          .option('password', passwd) \\\n",
    "          .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "          .save()\n",
    "df_tipo_vuelo.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "23abac95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+-------------+\n",
      "|Codigo_Trafico|Descripcion|IDTipoTrafico|\n",
      "+--------------+-----------+-------------+\n",
      "|             N|   Nacional|            0|\n",
      "+--------------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creacion tabla DimTipo_Trafico\n",
    "df_trafico=dfvuelosnew.selectExpr('trafico as Codigo_Trafico')\n",
    "df_trafico=df_trafico.dropDuplicates()\n",
    "df_trafico=df_trafico.withColumn(\"Descripcion\", \\\n",
    "   when((df_trafico.Codigo_Trafico ==\"I\"), \"Internacional\") \\\n",
    "   .when((df_trafico.Codigo_Trafico ==\"N\"),\"Nacional\") \\\n",
    "   .when((df_trafico.Codigo_Trafico ==\"E\"),\"Externo\") \\\n",
    "   .otherwise(\"nan\") \\\n",
    "  )\n",
    "df_trafico=df_trafico.sort(col(\"Codigo_Trafico\"))\n",
    "df_trafico = df_trafico.coalesce(1).withColumn(\"IDTipoTrafico\", mid())\n",
    "df_trafico.toPandas().to_csv('ModelExt/DimTipoTrafico.csv')\n",
    "df_trafico.select('*').write.format('jdbc') \\\n",
    "          .mode('overwrite') \\\n",
    "          .option('url', db_multidimensional_connection_string) \\\n",
    "          .option('dbtable', 'DimTipo_Trafico') \\\n",
    "          .option('user', user) \\\n",
    "          .option('password', passwd) \\\n",
    "          .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "          .save()\n",
    "df_trafico.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "567ec9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|       NombreEmpresa|IDEmpresa|\n",
      "+--------------------+---------+\n",
      "| AER CARIBE LIMITADA|        0|\n",
      "|          AERO APOYO|        1|\n",
      "|AERO SERVICIOS ES...|        2|\n",
      "|AERO TAXI GUAYMAR...|        3|\n",
      "|AEROCHARTER ANDIN...|        4|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creacion tabla DimEmpresaTransportadora\n",
    "df_empresatrans1=dfvuelosnew.selectExpr('empresa as NombreEmpresa')\n",
    "df_empresatrans1=df_empresatrans1.dropDuplicates()\n",
    "df_empresatrans1=df_empresatrans1.sort(col(\"NombreEmpresa\"))\n",
    "nandf = spark.createDataFrame([('nan', )], df_empresatrans1.columns)\n",
    "df_empresatrans1 = df_empresatrans1.union(nandf)\n",
    "df_empresatrans1 = df_empresatrans1.coalesce(1).withColumn(\"IDEmpresa\", mid())\n",
    "df_empresatrans1.toPandas().to_csv('ModelExt/DimEmpresaTransportadora.csv')\n",
    "df_empresatrans1.select('*').write.format('jdbc') \\\n",
    "          .mode('overwrite') \\\n",
    "          .option('url', db_multidimensional_connection_string) \\\n",
    "          .option('dbtable', 'DimEmpresaTransportadora') \\\n",
    "          .option('user', user) \\\n",
    "          .option('password', passwd) \\\n",
    "          .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "          .save()\n",
    "df_empresatrans1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6dadf0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|NombreEquipo|IDEquipo|\n",
      "+------------+--------+\n",
      "|         318|       0|\n",
      "|         319|       1|\n",
      "|         330|       2|\n",
      "|         332|       3|\n",
      "|         727|       4|\n",
      "+------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creacion tabla DimTipo_Equipo\n",
    "df_tipoequipo=dfvuelosnew.selectExpr('tipo_equipo as NombreEquipo')\n",
    "df_tipoequipo=df_tipoequipo.dropDuplicates()\n",
    "df_tipoequipo=df_tipoequipo.sort(col(\"NombreEquipo\"))\n",
    "nandf = spark.createDataFrame([('nan', )], df_tipoequipo.columns)\n",
    "df_tipoequipo = df_tipoequipo.union(nandf)\n",
    "df_tipoequipo = df_tipoequipo.coalesce(1).withColumn(\"IDEquipo\", mid())\n",
    "df_tipoequipo.toPandas().to_csv('ModelExt/DimTipo_Equipo.csv')\n",
    "df_tipoequipo.select('*').write.format('jdbc') \\\n",
    "          .mode('overwrite') \\\n",
    "          .option('url', db_multidimensional_connection_string) \\\n",
    "          .option('dbtable', 'DimTipo_Equipo') \\\n",
    "          .option('user', user) \\\n",
    "          .option('password', passwd) \\\n",
    "          .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "          .save()\n",
    "df_tipoequipo.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d50e0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+----+-----+\n",
      "|Codigo|Departamento|Anio|  PIB|\n",
      "+------+------------+----+-----+\n",
      "|    91|    Amazonas|2014|  157|\n",
      "|    91|    Amazonas|2015|  178|\n",
      "|    91|    Amazonas|2016|  199|\n",
      "|    91|    Amazonas|2017|  213|\n",
      "|    91|    Amazonas|2018|  224|\n",
      "|    91|    Amazonas|2019|  238|\n",
      "|    91|    Amazonas|2020|  174|\n",
      "|     5|   Antioquia|2014|16705|\n",
      "|     5|   Antioquia|2015|18734|\n",
      "|     5|   Antioquia|2016|21462|\n",
      "|     5|   Antioquia|2017|22797|\n",
      "|     5|   Antioquia|2018|24232|\n",
      "|     5|   Antioquia|2019|26405|\n",
      "|     5|   Antioquia|2020|23337|\n",
      "|    81|      Arauca|2014|  411|\n",
      "|    81|      Arauca|2015|  457|\n",
      "|    81|      Arauca|2016|  517|\n",
      "|    81|      Arauca|2017|  514|\n",
      "|    81|      Arauca|2018|  542|\n",
      "|    81|      Arauca|2019|  580|\n",
      "+------+------------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TransformacionInformacionPIB\n",
    "dfPIBUnpivot=dfPIB.withColumnRenamed(\"DEPARTAMENTOS\",\"Departamento\").withColumnRenamed(\"2014\",\"Ano2014\").withColumnRenamed(\"2015\",\"Ano2015\").withColumnRenamed(\"2016\",\"Ano2016\")\\\n",
    "             .withColumnRenamed(\"2017\",\"Ano2017\").withColumnRenamed(\"2018\",\"Ano2018\").withColumnRenamed(\"2019\",\"Ano2019\")\\\n",
    "             .withColumnRenamed(\"2020\",\"Ano2020\")\n",
    "unpivotExpr = \"stack(7, 'Ano2014',Ano2014, 'Ano2015', Ano2015, 'Ano2016', Ano2016,'Ano2017', Ano2017,'Ano2018', Ano2018,'Ano2019', Ano2019,'Ano2020', Ano2020) as (Anio,PIB)\"\n",
    "dfPIBUnpivot = dfPIBUnpivot.selectExpr(\"Codigo\",\"Departamento\", unpivotExpr).where(\"PIB is not null\")    \n",
    "dfPIBUnpivot=dfPIBUnpivot.withColumn('Anio', substring('Anio', 4,4))\n",
    "dfPIBUnpivot=dfPIBUnpivot.withColumn('Departamento', \n",
    "    when(dfPIBUnpivot.Departamento.startswith('San Andrés'),'San Andrés islas') \\\n",
    "   .when(dfPIBUnpivot.Departamento.startswith('BOG'),'Bogotá, D.C.') \\\n",
    "   .otherwise(dfPIBUnpivot.Departamento))\n",
    "dfPIBUnpivot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dddbec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para el ejemplo del manejo de historia, se divide el datafranme de PIB por año, \n",
    "#con el fin de crear una base, y actualizaciones\n",
    "dfBIPparte1 = dfPIBUnpivot.filter(dfPIBUnpivot.Anio==\"2014\")\n",
    "dfBIPparte2 = dfPIBUnpivot.filter(dfPIBUnpivot.Anio==\"2015\")\n",
    "dfBIPparte3 = dfPIBUnpivot.filter(dfPIBUnpivot.Anio==\"2016\")\n",
    "dfBIPparte4 = dfPIBUnpivot.filter(dfPIBUnpivot.Anio==\"2017\")\n",
    "dfBIPparte5 = dfPIBUnpivot.filter(dfPIBUnpivot.Anio==\"2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7a523078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualización tabla Dim InformacionPIB\n",
    "from pyspark.sql.types import DateType\n",
    "def actualizar_historia_PIB(df_a_cargar):\n",
    "    \n",
    "    tablaDWH=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT *\n",
    "    FROM  DimInformacionPIB) AS Temp_DimInformacionPIB''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load()\n",
    "    \n",
    "    df=df_a_cargar.selectExpr('Departamento as Departamento', 'Anio as Anio', 'PIB as PIB')\n",
    "    if tablaDWH.count()==0:\n",
    "        \n",
    "        df=df.withColumn(\"FechaInicioVigencia\",lit(\"1900-01-01\"))\n",
    "        df=df.withColumn(\"FechaFinVigencia\",lit(\"2300-01-01\"))\n",
    "        df=df.withColumn(\"VersionDelRegistro\",lit(\"S\"))\n",
    "        df=df.dropDuplicates()\n",
    "        df=df.sort(col(\"Departamento\"))\n",
    "        df = df.coalesce(1).withColumn(\"IDPIB\", mid())\n",
    "        df.createOrReplaceTempView(\"df\")\n",
    "        df = spark.sql(\"SELECT INT(IDPIB),STRING(Departamento),INT(PIB), DATE(FechaInicioVigencia),\\\n",
    "                       DATE(FechaFinVigencia), STRING(VersionDelRegistro),INT(Anio) from df\")\n",
    "        \n",
    "        df.toPandas().to_csv('ModelExt/DimInformacionPIB.csv')\n",
    "        x=df.count()\n",
    "        df.select('*').write.format('jdbc') \\\n",
    "          .mode('overwrite') \\\n",
    "          .option('url', db_multidimensional_connection_string) \\\n",
    "          .option('dbtable', 'DimInformacionPIB') \\\n",
    "          .option('user', user) \\\n",
    "          .option('password', passwd) \\\n",
    "          .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "          .save()\n",
    "    else:\n",
    "        tablaDWH.persist()\n",
    "        df_fechas_antiguas=tablaDWH.selectExpr('Departamento','Departamento as DepartamentoAnt')\n",
    "        df_fechas_antiguas=df_fechas_antiguas.dropDuplicates()\n",
    "        df_nuevo=df.selectExpr('Departamento','Anio as AnioNuevo')\n",
    "        df_nuevo=df_nuevo.dropDuplicates()\n",
    "        df_temp=tablaDWH.join(df_nuevo, how = 'left', on = 'Departamento')\n",
    "        #registros que no tienen actualizacion\n",
    "        df_temp.persist()\n",
    "        df_mantener=df_temp.filter(df_temp.AnioNuevo.isNull())\n",
    "        df_mantener=df_mantener.drop('AnioNuevo')\n",
    "        df_mantener=df_mantener.withColumn(\"Origen\",lit(\"Mantener\"))\n",
    "        #registros que si tienen actualización\n",
    "        df_actualizar=df_temp.filter(df_temp.AnioNuevo.isNotNull())\n",
    "        #registros viejos que no van a cambiar\n",
    "        df_actualizar.persist()\n",
    "        df_actualizar_registrosviejos=df_actualizar.filter(df_actualizar.VersionDelRegistro==\"N\")\n",
    "        df_actualizar_registrosviejos=df_actualizar_registrosviejos.drop('AnioNuevo')\n",
    "        #actualización de registros que eran vigentes\n",
    "        df_actualizar_registrosvigentes=df_actualizar.filter(df_actualizar.VersionDelRegistro==\"S\")\n",
    "        df_actualizar_registrosvigentes=df_actualizar_registrosvigentes.withColumn(\"VersionDelRegistro\",lit(\"N\"))\n",
    "        df_actualizar_registrosvigentes=df_actualizar_registrosvigentes.withColumn(\"FechaFinVigencia\",\n",
    "                                                                                    sf.concat(sf.col('Anio'),sf.lit('-12-31'))\n",
    "                                                                                   )    \n",
    "        df_actualizar_registrosvigentes=df_actualizar_registrosvigentes.drop('AnioNuevo')\n",
    "        #registros nuevos para ingresar a la base\n",
    "        #Encontar llave máxima\n",
    "        max_key = tablaDWH.agg({\"IDPIB\": \"max\"}).collect()[0][0]\n",
    "        df_nuevos_registros=df.alias('df_nuevos_registros')\n",
    "        df_nuevos_registros=df_nuevos_registros.join(df_fechas_antiguas,how = 'left', on = 'Departamento')\n",
    "        df_nuevos_registros=df_nuevos_registros.withColumn(\"FechaInicioVigencia\",when(df_nuevos_registros.DepartamentoAnt.isNull(),\\\n",
    "                                                                                     '1900-01-01')\\\n",
    "                                                           .otherwise(sf.concat(sf.col('Anio'),sf.lit('-01-01'))))\n",
    "        df_nuevos_registros=df_nuevos_registros.withColumn(\"FechaFinVigencia\",lit(\"2300-01-01\"))\n",
    "        df_nuevos_registros=df_nuevos_registros.withColumn(\"VersionDelRegistro\",lit(\"S\"))\n",
    "        df_nuevos_registros = df_nuevos_registros.withColumn('IDPIB',  mid() + max_key+1)\n",
    "        #unir en un solo dataframe\n",
    "        df_mantener.createOrReplaceTempView(\"df_mantener\")\n",
    "        df_mantener = spark.sql(\"SELECT INT(IDPIB) ,STRING(Departamento),INT(PIB), DATE(FechaInicioVigencia),\\\n",
    "                       DATE(FechaFinVigencia), STRING(VersionDelRegistro),INT(Anio) from df_mantener\")\n",
    "        \n",
    "        df_actualizar_registrosviejos.createOrReplaceTempView(\"df_actualizar_registrosviejos\")\n",
    "        df_actualizar_registrosviejos = spark.sql(\"SELECT INT(IDPIB) ,STRING(Departamento),INT(PIB), DATE(FechaInicioVigencia),\\\n",
    "                       DATE(FechaFinVigencia), STRING(VersionDelRegistro),INT(Anio) from df_actualizar_registrosviejos\")\n",
    "        \n",
    "        df_actualizar_registrosvigentes.createOrReplaceTempView(\"df_actualizar_registrosvigentes\")\n",
    "        df_actualizar_registrosvigentes = spark.sql(\"SELECT INT(IDPIB) ,STRING(Departamento),INT(PIB), DATE(FechaInicioVigencia),\\\n",
    "                       DATE(FechaFinVigencia), STRING(VersionDelRegistro),INT(Anio) from df_actualizar_registrosvigentes\")\n",
    "        \n",
    "        df_nuevos_registros.createOrReplaceTempView(\"df_nuevos_registros\")\n",
    "        df_nuevos_registros = spark.sql(\"SELECT INT(IDPIB) ,STRING(Departamento),INT(PIB), DATE(FechaInicioVigencia),\\\n",
    "                       DATE(FechaFinVigencia), STRING(VersionDelRegistro),INT(Anio) from df_nuevos_registros\")\n",
    "        \n",
    "        df2 = df_nuevos_registros.union(df_mantener)\n",
    "        df2 = df2.union(df_actualizar_registrosviejos)\n",
    "        df2 = df2.union(df_actualizar_registrosvigentes)\n",
    "        df2.toPandas().to_csv('ModelExt/DimInformacionPIB.csv')\n",
    "        x=df2.count()\n",
    "        df2.select('*').write.format('jdbc') \\\n",
    "          .mode('overwrite') \\\n",
    "          .option('url', db_multidimensional_connection_string) \\\n",
    "          .option('dbtable', 'DimInformacionPIB') \\\n",
    "          .option('user', user) \\\n",
    "          .option('password', passwd) \\\n",
    "          .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "          .save()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c0cc5c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conteo inicial base de datos : 0\n",
      "conteo primera carga dataframe : 33\n",
      "conteo primera carga base de datos : 33\n",
      "conteo segunda carga dataframe : 66\n",
      "conteo segunda carga base de datos : 66\n",
      "conteo tercera carga dataframe : 99\n",
      "conteo tercera carga base de datos : 99\n",
      "conteo tercera carga dataframe : 132\n",
      "conteo tercera carga base de datos : 132\n"
     ]
    }
   ],
   "source": [
    "#Validación proceso de carga PIB con historia\n",
    "DimPIBHistoria=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT *\n",
    "    FROM  DimInformacionPIB) AS Temp_DimInformacionPIB''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load()\n",
    "print(\"conteo inicial base de datos : {0}\".format(DimPIBHistoria.count()))\n",
    "\n",
    "x=actualizar_historia_PIB(dfBIPparte1)\n",
    "print(\"conteo primera carga dataframe : {0}\".format(x))\n",
    "\n",
    "DimPIBHistoria=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT *\n",
    "    FROM  DimInformacionPIB) AS Temp_DimInformacionPIB''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load()\n",
    "DimPIBHistoria.count()  \n",
    "print(\"conteo primera carga base de datos : {0}\".format(DimPIBHistoria.count()))\n",
    "      \n",
    "x=actualizar_historia_PIB(dfBIPparte2)\n",
    "print(\"conteo segunda carga dataframe : {0}\".format(x))\n",
    "\n",
    "DimPIBHistoria=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT *\n",
    "    FROM  DimInformacionPIB) AS Temp_DimInformacionPIB''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load()\n",
    "DimPIBHistoria.count()  \n",
    "print(\"conteo segunda carga base de datos : {0}\".format(DimPIBHistoria.count()))\n",
    "\n",
    "x=actualizar_historia_PIB(dfBIPparte3)\n",
    "print(\"conteo tercera carga dataframe : {0}\".format(x))\n",
    "\n",
    "DimPIBHistoria=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT *\n",
    "    FROM  DimInformacionPIB) AS Temp_DimInformacionPIB''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load()\n",
    "DimPIBHistoria.count()  \n",
    "print(\"conteo tercera carga base de datos : {0}\".format(DimPIBHistoria.count()))\n",
    "\n",
    "x=actualizar_historia_PIB(dfBIPparte4)\n",
    "print(\"conteo tercera carga dataframe : {0}\".format(x))\n",
    "\n",
    "DimPIBHistoria=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT *\n",
    "    FROM  DimInformacionPIB) AS Temp_DimInformacionPIB''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load()\n",
    "DimPIBHistoria.count()  \n",
    "print(\"conteo tercera carga base de datos : {0}\".format(DimPIBHistoria.count()))\n",
    "\n",
    "\n",
    "x=actualizar_historia_PIB(dfBIPparte5)\n",
    "print(\"conteo tercera carga dataframe : {0}\".format(x))\n",
    "\n",
    "DimPIBHistoria=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT *\n",
    "    FROM  DimInformacionPIB) AS Temp_DimInformacionPIB''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load()\n",
    "DimPIBHistoria.count()  \n",
    "print(\"conteo tercera carga base de datos : {0}\".format(DimPIBHistoria.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e52d252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para el ejemplo del manejo de historia, se divide el datafranme de aeropuertos en 3, \n",
    "#con el fin de crear una base, y dos actualizaciones\n",
    "dfaeropuertosconhistoriaparte1 = dfaeropuertosconhistoria.filter(dfaeropuertosconhistoria.Ano==\"2014\")\n",
    "dfaeropuertosconhistoriaparte2 = dfaeropuertosconhistoria.filter(dfaeropuertosconhistoria.Ano==\"2015\")\n",
    "dfaeropuertosconhistoriaparte3 = dfaeropuertosconhistoria.filter(dfaeropuertosconhistoria.Ano==\"2016\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4b9d24cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+-----+-------------------+----------------+------------------+----+\n",
      "|IDPIB|Departamento|  PIB|FechaInicioVigencia|FechaFinVigencia|VersionDelRegistro|Anio|\n",
      "+-----+------------+-----+-------------------+----------------+------------------+----+\n",
      "|    0|    Amazonas|  157|         1900-01-01|      2014-12-31|                 N|2014|\n",
      "|    1|   Antioquia|16705|         1900-01-01|      2014-12-31|                 N|2014|\n",
      "|    2|      Arauca|  411|         1900-01-01|      2014-12-31|                 N|2014|\n",
      "|    3|   Atlántico| 6041|         1900-01-01|      2014-12-31|                 N|2014|\n",
      "|    4|Bogotá, D.C.|35338|         1900-01-01|      2014-12-31|                 N|2014|\n",
      "+-----+------------+-----+-------------------+----------------+------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "InfoPIB=spark.read.format('jdbc')\\\n",
    ".option('url', db_multidimensional_connection_string) \\\n",
    ".option('dbtable', '''(SELECT *\n",
    "FROM  DimInformacionPIB) AS Temp_DimInformacionPIB''') \\\n",
    ".option('user', user) \\\n",
    ".option('password', passwd) \\\n",
    ".option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    ".load()\n",
    "\n",
    "InfoPIB.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6b32c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualización tabla DimAeropuertoHistoria\n",
    "from pyspark.sql.types import DateType\n",
    "def actualizar_historia_aeropuertos(df_a_cargar):\n",
    "    \n",
    "    tablaDWH=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT *\n",
    "    FROM  DimAeropuertoHistoria) AS Temp_DimAeropuertoHistoria''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load()\n",
    "\n",
    "    \n",
    "    InfoPIB=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT *\n",
    "    FROM  DimInformacionPIB) AS Temp_DimInformacionPIB''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load()\n",
    "    InfoPIB.createOrReplaceTempView(\"InfoPIB\")\n",
    "    \n",
    "    df=df_a_cargar.selectExpr('sigla as Sigla', 'iata as IATA', 'nombre as NombreAeropuerto',\n",
    "                                          'municipio as Municipio','departamento as Departamento', 'categoria as Categoria',\n",
    "                                           'latitud as Latitud','longitud as Longitud', 'propietario as Propietario',\n",
    "                                           'explotador as Explotador','longitud_pista as LongitudPista',\n",
    "                                           'ancho_pista as AnchoPista', 'pbmo as PBMO', 'elevacion as Elevacion',\n",
    "                                           'resolucion as Resolucion','clase as Clase', 'tipo as Tipo', \n",
    "                                           'gcd_municipio as GCD_Municipio', 'gcd_departamento as GCD_Departamento',\n",
    "                                           'Ano as Anio')\n",
    "    if tablaDWH.count()==0:\n",
    "        \n",
    "        df=df.withColumn(\"FechaInicioVigencia\",lit(\"1900-01-01\"))\n",
    "        df=df.withColumn(\"FechaFinVigencia\",lit(\"2300-01-01\"))\n",
    "        df=df.withColumn(\"VersionDelRegistro\",lit(\"S\"))\n",
    "        df=df.dropDuplicates()\n",
    "        df=df.sort(col(\"Sigla\"))\n",
    "        df = df.coalesce(1).withColumn(\"IDAeropuerto\", mid())\n",
    "        df.createOrReplaceTempView(\"df\")\n",
    "        df = spark.sql(\"SELECT INT(IDAeropuerto), STRING(Sigla), STRING(IATA), STRING(NombreAeropuerto),\\\n",
    "                        STRING(Categoria),DOUBLE(Latitud), DOUBLE(Longitud),STRING(Municipio), STRING(df.Departamento), \\\n",
    "                         STRING(Propietario),STRING(Explotador),INT(LongitudPista), INT(AnchoPista),\\\n",
    "                        STRING(PBMO),INT(Elevacion), STRING(Resolucion), STRING(Clase),\\\n",
    "                        STRING(Tipo),STRING(GCD_Municipio), STRING(GCD_Departamento), DATE(df.FechaInicioVigencia),\\\n",
    "                       DATE(df.FechaFinVigencia), STRING(df.VersionDelRegistro),INT(df.Anio), INT(InfoPIB.IDPIB) from df\\\n",
    "                       left join InfoPIB on InfoPIB.Departamento= df.Departamento and\\\n",
    "                             InfoPIB.Anio= df.Anio\")\n",
    "        \n",
    "        df.toPandas().to_csv('ModelExt/DimAeropuertoHistoria.csv')\n",
    "        x=df.count()\n",
    "        df.select('*').write.format('jdbc') \\\n",
    "          .mode('overwrite') \\\n",
    "          .option('url', db_multidimensional_connection_string) \\\n",
    "          .option('dbtable', 'DimAeropuertoHistoria') \\\n",
    "          .option('user', user) \\\n",
    "          .option('password', passwd) \\\n",
    "          .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "          .save()\n",
    "    else:\n",
    "        tablaDWH.persist()\n",
    "        df_fechas_antiguas=tablaDWH.selectExpr('Sigla','Sigla as SiglaAnt')\n",
    "        df_fechas_antiguas=df_fechas_antiguas.dropDuplicates()\n",
    "        df_nuevo=df.selectExpr('Sigla','Anio as AnioNuevo')\n",
    "        df_nuevo=df_nuevo.dropDuplicates()\n",
    "        df_temp=tablaDWH.join(df_nuevo, how = 'left', on = 'Sigla')\n",
    "        #registros que no tienen actualizacion\n",
    "        df_temp.persist()\n",
    "        df_mantener=df_temp.filter(df_temp.AnioNuevo.isNull())\n",
    "        df_mantener=df_mantener.drop('AnioNuevo')\n",
    "        df_mantener=df_mantener.withColumn(\"Origen\",lit(\"Mantener\"))\n",
    "        #registros que si tienen actualización\n",
    "        df_actualizar=df_temp.filter(df_temp.AnioNuevo.isNotNull())\n",
    "        #registros viejos que no van a cambiar\n",
    "        df_actualizar.persist()\n",
    "        df_actualizar_registrosviejos=df_actualizar.filter(df_actualizar.VersionDelRegistro==\"N\")\n",
    "        df_actualizar_registrosviejos=df_actualizar_registrosviejos.drop('AnioNuevo')\n",
    "        #actualización de registros que eran vigentes\n",
    "        df_actualizar_registrosvigentes=df_actualizar.filter(df_actualizar.VersionDelRegistro==\"S\")\n",
    "        df_actualizar_registrosvigentes=df_actualizar_registrosvigentes.withColumn(\"VersionDelRegistro\",lit(\"N\"))\n",
    "        df_actualizar_registrosvigentes=df_actualizar_registrosvigentes.withColumn(\"FechaFinVigencia\",\n",
    "                                                                                    sf.concat(sf.col('AnioNuevo')-1,sf.lit('-12-31'))\n",
    "                                                                                   )    \n",
    "        df_actualizar_registrosvigentes=df_actualizar_registrosvigentes.drop('AnioNuevo')\n",
    "        #registros nuevos para ingresar a la base\n",
    "        #Encontar llave máxima\n",
    "        max_key = tablaDWH.agg({\"IDAeropuerto\": \"max\"}).collect()[0][0]\n",
    "        df_nuevos_registros=df.alias('df_nuevos_registros')\n",
    "        df_nuevos_registros=df_nuevos_registros.join(df_fechas_antiguas,how = 'left', on = 'Sigla')\n",
    "        df_nuevos_registros=df_nuevos_registros.withColumn(\"FechaInicioVigencia\",when(df_nuevos_registros.SiglaAnt.isNull(),\\\n",
    "                                                                                     '1900-01-01')\\\n",
    "                                                           .otherwise(sf.concat(sf.col('Anio'),sf.lit('-01-01'))))\n",
    "        df_nuevos_registros=df_nuevos_registros.withColumn(\"FechaFinVigencia\",lit(\"2300-01-01\"))\n",
    "        df_nuevos_registros=df_nuevos_registros.withColumn(\"VersionDelRegistro\",lit(\"S\"))\n",
    "        df_nuevos_registros = df_nuevos_registros.withColumn('IDAeropuerto',  mid() + max_key+1)\n",
    "        #unir en un solo dataframe\n",
    "        df_mantener.createOrReplaceTempView(\"df_mantener\")\n",
    "        df_mantener = spark.sql(\"SELECT INT(IDAeropuerto), STRING(Sigla), STRING(IATA), STRING(NombreAeropuerto),\\\n",
    "                        STRING(Categoria),DOUBLE(Latitud), DOUBLE(Longitud),STRING(Municipio), STRING(df_mantener.Departamento), \\\n",
    "                         STRING(Propietario),STRING(Explotador),INT(LongitudPista), INT(AnchoPista),\\\n",
    "                        STRING(PBMO),INT(Elevacion), STRING(Resolucion), STRING(Clase),\\\n",
    "                        STRING(Tipo),STRING(GCD_Municipio), STRING(GCD_Departamento), DATE(df_mantener.FechaInicioVigencia),\\\n",
    "                       DATE(df_mantener.FechaFinVigencia), STRING(df_mantener.VersionDelRegistro),INT(df_mantener.Anio), INT(InfoPIB.IDPIB) from df_mantener\\\n",
    "                       left join InfoPIB on InfoPIB.Departamento= df_mantener.Departamento and\\\n",
    "                             InfoPIB.Anio= df_mantener.Anio\")\n",
    "        \n",
    "        df_actualizar_registrosviejos.createOrReplaceTempView(\"df_actualizar_registrosviejos\")\n",
    "        df_actualizar_registrosviejos = spark.sql(\"SELECT INT(IDAeropuerto), STRING(Sigla), STRING(IATA), STRING(NombreAeropuerto),\\\n",
    "                        STRING(Categoria),DOUBLE(Latitud), DOUBLE(Longitud),STRING(Municipio), STRING(df_actualizar_registrosviejos.Departamento), \\\n",
    "                         STRING(Propietario),STRING(Explotador),INT(LongitudPista), INT(AnchoPista),\\\n",
    "                        STRING(PBMO),INT(Elevacion), STRING(Resolucion), STRING(Clase),\\\n",
    "                        STRING(Tipo),STRING(GCD_Municipio), STRING(GCD_Departamento), DATE(df_actualizar_registrosviejos.FechaInicioVigencia),\\\n",
    "                       DATE(df_actualizar_registrosviejos.FechaFinVigencia), STRING(df_actualizar_registrosviejos.VersionDelRegistro),INT(df_actualizar_registrosviejos.Anio), INT(InfoPIB.IDPIB) from df_actualizar_registrosviejos\\\n",
    "                       left join InfoPIB on InfoPIB.Departamento= df_actualizar_registrosviejos.Departamento and\\\n",
    "                             InfoPIB.Anio= df_actualizar_registrosviejos.Anio\")\n",
    "        \n",
    "        df_actualizar_registrosvigentes.createOrReplaceTempView(\"df_actualizar_registrosvigentes\")\n",
    "        df_actualizar_registrosvigentes = spark.sql(\"SELECT INT(IDAeropuerto), STRING(Sigla), STRING(IATA), STRING(NombreAeropuerto),\\\n",
    "                        STRING(Categoria),DOUBLE(Latitud), DOUBLE(Longitud),STRING(Municipio), STRING(df_actualizar_registrosvigentes.Departamento), \\\n",
    "                         STRING(Propietario),STRING(Explotador),INT(LongitudPista), INT(AnchoPista),\\\n",
    "                        STRING(PBMO),INT(Elevacion), STRING(Resolucion), STRING(Clase),\\\n",
    "                        STRING(Tipo),STRING(GCD_Municipio), STRING(GCD_Departamento), DATE(df_actualizar_registrosvigentes.FechaInicioVigencia),\\\n",
    "                       DATE(df_actualizar_registrosvigentes.FechaFinVigencia), STRING(df_actualizar_registrosvigentes.VersionDelRegistro),INT(df_actualizar_registrosvigentes.Anio), INT(InfoPIB.IDPIB) from df_actualizar_registrosvigentes\\\n",
    "                       left join InfoPIB on InfoPIB.Departamento= df_actualizar_registrosvigentes.Departamento and\\\n",
    "                             InfoPIB.Anio= df_actualizar_registrosvigentes.Anio\")\n",
    "        \n",
    "        df_nuevos_registros.createOrReplaceTempView(\"df_nuevos_registros\")\n",
    "        df_nuevos_registros = spark.sql(\"SELECT INT(IDAeropuerto), STRING(Sigla), STRING(IATA), STRING(NombreAeropuerto),\\\n",
    "                        STRING(Categoria),DOUBLE(Latitud), DOUBLE(Longitud),STRING(Municipio), STRING(df_nuevos_registros.Departamento), \\\n",
    "                         STRING(Propietario),STRING(Explotador),INT(LongitudPista), INT(AnchoPista),\\\n",
    "                        STRING(PBMO),INT(Elevacion), STRING(Resolucion), STRING(Clase),\\\n",
    "                        STRING(Tipo),STRING(GCD_Municipio), STRING(GCD_Departamento), DATE(df_nuevos_registros.FechaInicioVigencia),\\\n",
    "                       DATE(df_nuevos_registros.FechaFinVigencia), STRING(df_nuevos_registros.VersionDelRegistro),INT(df_nuevos_registros.Anio), INT(InfoPIB.IDPIB) from df_nuevos_registros\\\n",
    "                       left join InfoPIB on InfoPIB.Departamento= df_nuevos_registros.Departamento and\\\n",
    "                             InfoPIB.Anio= df_nuevos_registros.Anio\")\n",
    "        \n",
    "        df2 = df_nuevos_registros.union(df_mantener)\n",
    "        df2 = df2.union(df_actualizar_registrosviejos)\n",
    "        df2 = df2.union(df_actualizar_registrosvigentes)\n",
    "        \n",
    "        df2.toPandas().to_csv('ModelExt/DimAeropuertoHistoria.csv')\n",
    "        x=df2.count()\n",
    "        df2.select('*').write.format('jdbc') \\\n",
    "          .mode('overwrite') \\\n",
    "          .option('url', db_multidimensional_connection_string) \\\n",
    "          .option('dbtable', 'DimAeropuertoHistoria') \\\n",
    "          .option('user', user) \\\n",
    "          .option('password', passwd) \\\n",
    "          .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "          .save()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "deca3efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conteo inicial base de datos : 0\n",
      "conteo primera carga dataframe : 264\n",
      "conteo primera carga base de datos : 264\n",
      "conteo segunda carga dataframe : 562\n",
      "conteo segunda carga base de datos : 562\n",
      "conteo tercera carga dataframe : 860\n",
      "conteo tercera carga base de datos : 860\n"
     ]
    }
   ],
   "source": [
    "#Validación proceso de carga con historia\n",
    "DimAeropuertoHistoria=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT *\n",
    "    FROM  DimAeropuertoHistoria) AS Temp_DimAeropuertoHistoria''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load()\n",
    "print(\"conteo inicial base de datos : {0}\".format(DimAeropuertoHistoria.count()))\n",
    "\n",
    "x=actualizar_historia_aeropuertos(dfaeropuertosconhistoriaparte1)\n",
    "print(\"conteo primera carga dataframe : {0}\".format(x))\n",
    "\n",
    "DimAeropuertoHistoria=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT *\n",
    "    FROM  DimAeropuertoHistoria) AS Temp_DimAeropuertoHistoria''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load()\n",
    "DimAeropuertoHistoria.count()  \n",
    "print(\"conteo primera carga base de datos : {0}\".format(DimAeropuertoHistoria.count()))\n",
    "      \n",
    "x=actualizar_historia_aeropuertos(dfaeropuertosconhistoriaparte2)\n",
    "print(\"conteo segunda carga dataframe : {0}\".format(x))\n",
    "\n",
    "DimAeropuertoHistoria=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT *\n",
    "    FROM  DimAeropuertoHistoria) AS Temp_DimAeropuertoHistoria''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load()\n",
    "DimAeropuertoHistoria.count()  \n",
    "print(\"conteo segunda carga base de datos : {0}\".format(DimAeropuertoHistoria.count()))\n",
    "\n",
    "x=actualizar_historia_aeropuertos(dfaeropuertosconhistoriaparte3)\n",
    "print(\"conteo tercera carga dataframe : {0}\".format(x))\n",
    "\n",
    "DimAeropuertoHistoria=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT *\n",
    "    FROM  DimAeropuertoHistoria) AS Temp_DimAeropuertoHistoria''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load()\n",
    "DimAeropuertoHistoria.count()  \n",
    "print(\"conteo tercera carga base de datos : {0}\".format(DimAeropuertoHistoria.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4d760271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "860"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfaeropuertosconhistoria.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eba49304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+---------------+--------------------+---------+-------+--------+----------+------------+--------------------+-----------+-------------+----------+-----+---------+----------+-----+----------+-------------+----------------+-------------------+----------------+------------------+----+-----+\n",
      "|IDAeropuerto|Sigla|           IATA|    NombreAeropuerto|Categoria|Latitud|Longitud| Municipio|Departamento|         Propietario| Explotador|LongitudPista|AnchoPista| PBMO|Elevacion|Resolucion|Clase|      Tipo|GCD_Municipio|GCD_Departamento|FechaInicioVigencia|FechaFinVigencia|VersionDelRegistro|Anio|IDPIB|\n",
      "+------------+-----+---------------+--------------------+---------+-------+--------+----------+------------+--------------------+-----------+-------------+----------+-----+---------+----------+-----+----------+-------------+----------------+-------------------+----------------+------------------+----+-----+\n",
      "|         587|  7GY|no-especificado|         LAS ACACIAS|Aeródromo| 5.0949|-73.9054|   Nemocón|Cundinamarca|JUAN BERNANDO SAN...|   EL MISMO|         1289|        14|10000|     8431|   439,000|   3A|   Público|        25486|              25|         2016-01-01|      2300-01-01|                 S|2016|   80|\n",
      "|         689|  9DI|no-especificado|          SAN FELIPE|Aeródromo|  1.915|-67.0776|San Felipe|     Guainía|         GOBERNACION|GOBERNACION|         3701|        59|25000|      312|   545,000|   1A| Aerocivil|        94883|              94|         2016-01-01|      2300-01-01|                 S|2016|   81|\n",
      "|         593|  7HE|no-especificado|GUACHARACAS (COLO...|Aeródromo| 4.7371|-74.8021|   Beltrán|Cundinamarca| EMPRESA GUACHARACAS|  CCA. LTDA|            3|         0| 3000|      797| 5,920,000|   1A| Aerocivil|        25086|              25|         2016-01-01|      2300-01-01|                 S|2016|   80|\n",
      "|         603|  7HQ|no-especificado|GENERAL ADELMO RU...|Aeródromo|   4.35|-74.7511|  Ricaurte|Cundinamarca|  EDUARDO A. VIVEROS|       ACAF|           69|        71|  500|      987|    46,000|   1A| Aerocivil|        25612|              25|         2016-01-01|      2300-01-01|                 S|2016|   80|\n",
      "|         750|  A01|no-especificado|        CAMPO ALEGRE|Aeródromo| 1.8653|-69.0101|   Inírida|     Guainía|         GOBERNACION|GOBERNACION|         2341|        50| 2000|      577| 1,333,000|   1A|Fumigación|        94001|              94|         2016-01-01|      2300-01-01|                 S|2016|   81|\n",
      "+------------+-----+---------------+--------------------+---------+-------+--------+----------+------------+--------------------+-----------+-------------+----------+-----+---------+----------+-----+----------+-------------+----------------+-------------------+----------------+------------------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DimAeropuertoHistoria.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c3abd2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------+---------+--------+------------------+-------------------+------+---------+----------+-----------+----------+---+\n",
      "|IDFecha|IDTipoVuelo|IDTipoTrafico|IDEmpresa|IDEquipo|IDAeropuertoOrigen|IDAeropuertoDestino|Vuelos|Pasajeros|CargaBordo|TotalSillas|TotalCarga| ID|\n",
      "+-------+-----------+-------------+---------+--------+------------------+-------------------+------+---------+----------+-----------+----------+---+\n",
      "|     76|          3|            0|       50|      42|               828|                674|     1|        0|         0|          0|         0|  0|\n",
      "|     17|          3|            0|       13|      50|               183|                 97|     1|        2|       200|          2|       200|  1|\n",
      "|     44|          3|            0|       62|      52|               211|                 25|     1|        5|        40|          5|        40|  2|\n",
      "|     24|          3|            0|       69|      50|               183|                 53|     1|        2|         0|          2|         0|  3|\n",
      "|     38|          3|            0|        1|      50|               211|                 53|     1|        1|         0|          1|         0|  4|\n",
      "+-------+-----------+-------------+---------+--------+------------------+-------------------+------+---------+----------+-----------+----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creacion Tabla de Hechos Vuelos\n",
    "import pyspark.sql.functions as F\n",
    "df_aeropuertoorigen=DimAeropuertoHistoria.selectExpr('Sigla as origen','Anio','FechaInicioVigencia',\n",
    "                                                     'FechaFinVigencia','IDAeropuerto as IDAeropuertoOrigen')\n",
    "df_aeropuertodestino=DimAeropuertoHistoria.selectExpr('Sigla as destino','Anio','FechaInicioVigencia',\n",
    "                                                      'FechaFinVigencia','IDAeropuerto as IDAeropuertoDestino')\n",
    "\n",
    "df_hechos_vuelos=dfvuelosnew.alias('df_hechos_vuelos')\n",
    "columns = ['vuelos', 'sillas','pasajeros','carga_bordo','carga_ofrecida']\n",
    "for column in columns:\n",
    "    df_hechos_vuelos = df_hechos_vuelos.withColumn(column,F.when(F.isnan(F.col(column)),0).otherwise(F.col(column)))\n",
    "df_hechos_vuelos= df_hechos_vuelos.withColumn(\"relativedate\",sf.concat(sf.col('ano'),lit(\"-\"),sf.col('mes'),sf.lit('-01')))\n",
    "df_hechos_vuelos= df_hechos_vuelos.withColumn(\"vuelos\",df_hechos_vuelos.vuelos.cast('int'))\n",
    "df_hechos_vuelos= df_hechos_vuelos.withColumn(\"sillas\",df_hechos_vuelos.sillas.cast('int'))\n",
    "df_hechos_vuelos= df_hechos_vuelos.withColumn(\"carga_ofrecida\",df_hechos_vuelos.carga_ofrecida.cast('int'))\n",
    "df_hechos_vuelos= df_hechos_vuelos.withColumn(\"carga_bordo\",df_hechos_vuelos.carga_bordo.cast('int'))\n",
    "df_hechos_vuelos= df_hechos_vuelos.withColumn(\"pasajeros\",df_hechos_vuelos.pasajeros.cast('int'))\n",
    "df_hechos_vuelos=df_hechos_vuelos.groupBy(\"relativedate\",\"ano\",\"mes\",\"origen\",\"destino\",\"tipo_equipo\",\"tipo_vuelo\",\"trafico\",\"empresa\") \\\n",
    "    .sum(\"vuelos\",\"pasajeros\",\"carga_bordo\",\"sillas\",\"carga_ofrecida\")\n",
    "df_hechos_vuelos=df_hechos_vuelos.withColumnRenamed(\"sum(vuelos)\", \"Vuelos\")\n",
    "df_hechos_vuelos=df_hechos_vuelos.withColumnRenamed(\"sum(pasajeros)\", \"Pasajeros\")\n",
    "df_hechos_vuelos=df_hechos_vuelos.withColumnRenamed(\"sum(carga_bordo)\", \"CargaBordo\")\n",
    "df_hechos_vuelos=df_hechos_vuelos.withColumnRenamed(\"sum(sillas)\", \"TotalSillas\")\n",
    "df_hechos_vuelos=df_hechos_vuelos.withColumnRenamed(\"sum(carga_ofrecida)\", \"TotalCarga\")\n",
    "df_hechos_vuelos.createOrReplaceTempView(\"df_hechos_vuelos\")\n",
    "df_aeropuertoorigen.createOrReplaceTempView(\"df_aeropuertoorigen\")\n",
    "df_aeropuertodestino.createOrReplaceTempView(\"df_aeropuertodestino\")\n",
    "df_fechames.createOrReplaceTempView(\"df_fechames\")\n",
    "df_tipo_vuelo.createOrReplaceTempView(\"df_tipo_vuelo\")\n",
    "df_empresatrans1.createOrReplaceTempView(\"df_empresatrans1\")\n",
    "df_trafico.createOrReplaceTempView(\"df_trafico\")\n",
    "df_tipoequipo.createOrReplaceTempView(\"df_tipoequipo\")\n",
    "df_hechos_vuelos = spark.sql(\"select  IDFecha,IDTipoVuelo,IDTipoTrafico,IDEmpresa,IDEquipo,IDAeropuertoOrigen,\\\n",
    "                             IDAeropuertoDestino,Vuelos,Pasajeros,CargaBordo,TotalSillas,TotalCarga from df_hechos_vuelos\\\n",
    "                             left join df_fechames on df_fechames.Anio= df_hechos_vuelos.ano and\\\n",
    "                             df_fechames.Mes= df_hechos_vuelos.mes\\\n",
    "                             left join df_tipo_vuelo on df_tipo_vuelo.CodigoVuelo= df_hechos_vuelos.tipo_vuelo\\\n",
    "                             left join df_trafico on df_trafico.Codigo_Trafico= df_hechos_vuelos.trafico\\\n",
    "                             left join df_empresatrans1 on df_empresatrans1.NombreEmpresa= df_hechos_vuelos.empresa\\\n",
    "                             left join df_tipoequipo on df_tipoequipo.NombreEquipo= df_hechos_vuelos.tipo_equipo\\\n",
    "                             left join df_aeropuertoorigen on df_aeropuertoorigen.origen= df_hechos_vuelos.origen and\\\n",
    "                             (df_hechos_vuelos.relativedate BETWEEN df_aeropuertoorigen.FechaInicioVigencia\\\n",
    "                             AND df_aeropuertoorigen.FechaFinVigencia)\\\n",
    "                             left join df_aeropuertodestino on df_aeropuertodestino.destino= df_hechos_vuelos.destino and\\\n",
    "                             (df_hechos_vuelos.relativedate BETWEEN df_aeropuertodestino.FechaInicioVigencia\\\n",
    "                             AND df_aeropuertodestino.FechaFinVigencia)\")\n",
    "df_hechos_vuelos = df_hechos_vuelos.coalesce(1).withColumn(\"ID\", mid())\n",
    "df_hechos_vuelos.toPandas().to_csv('ModelExt/FactVuelos.csv')\n",
    "df_hechos_vuelos.select('*').write.format('jdbc') \\\n",
    "          .mode('overwrite') \\\n",
    "          .option('url', db_multidimensional_connection_string) \\\n",
    "          .option('dbtable', 'FactVuelos') \\\n",
    "          .option('user', user) \\\n",
    "          .option('password', passwd) \\\n",
    "          .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "          .save()\n",
    "df_hechos_vuelos.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7824f51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DimFechaMes\n",
      "columnas de la tabla : 3\n",
      "filas de la tabla : 84\n",
      "+----+---+-------+\n",
      "|Anio|Mes|IDFecha|\n",
      "+----+---+-------+\n",
      "|2010|  1|      0|\n",
      "|2010|  2|      1|\n",
      "|2010|  3|      2|\n",
      "|2010|  4|      3|\n",
      "|2010|  5|      4|\n",
      "+----+---+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "DimTipoVuelo\n",
      "columnas de la tabla : 3\n",
      "filas de la tabla : 5\n",
      "+-----------+-----------+-----------+\n",
      "|CodigoVuelo|  TipoVuelo|IDTipoVuelo|\n",
      "+-----------+-----------+-----------+\n",
      "|          A|Adicionales|          0|\n",
      "|          C|    Charter|          1|\n",
      "|          R|    Regular|          2|\n",
      "|          T|       Taxi|          3|\n",
      "|        nan|        nan|          4|\n",
      "+-----------+-----------+-----------+\n",
      "\n",
      "None\n",
      "DimTipo_Trafico\n",
      "columnas de la tabla : 3\n",
      "filas de la tabla : 1\n",
      "+--------------+-----------+-------------+\n",
      "|Codigo_Trafico|Descripcion|IDTipoTrafico|\n",
      "+--------------+-----------+-------------+\n",
      "|             N|   Nacional|            0|\n",
      "+--------------+-----------+-------------+\n",
      "\n",
      "None\n",
      "DimEmpresaTransportadora\n",
      "columnas de la tabla : 2\n",
      "filas de la tabla : 87\n",
      "+--------------------+---------+\n",
      "|       NombreEmpresa|IDEmpresa|\n",
      "+--------------------+---------+\n",
      "| AER CARIBE LIMITADA|        0|\n",
      "|          AERO APOYO|        1|\n",
      "|AERO SERVICIOS ES...|        2|\n",
      "|AERO TAXI GUAYMAR...|        3|\n",
      "|AEROCHARTER ANDIN...|        4|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "DimTipo_Equipo\n",
      "columnas de la tabla : 2\n",
      "filas de la tabla : 112\n",
      "+------------+--------+\n",
      "|NombreEquipo|IDEquipo|\n",
      "+------------+--------+\n",
      "|         318|       0|\n",
      "|         319|       1|\n",
      "|         330|       2|\n",
      "|         332|       3|\n",
      "|         727|       4|\n",
      "+------------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "DimInformacionPIB\n",
      "columnas de la tabla : 7\n",
      "filas de la tabla : 132\n",
      "+-----+------------+-----+-------------------+----------------+------------------+----+\n",
      "|IDPIB|Departamento|  PIB|FechaInicioVigencia|FechaFinVigencia|VersionDelRegistro|Anio|\n",
      "+-----+------------+-----+-------------------+----------------+------------------+----+\n",
      "|    0|    Amazonas|  157|         1900-01-01|      2014-12-31|                 N|2014|\n",
      "|    1|   Antioquia|16705|         1900-01-01|      2014-12-31|                 N|2014|\n",
      "|    2|      Arauca|  411|         1900-01-01|      2014-12-31|                 N|2014|\n",
      "|    3|   Atlántico| 6041|         1900-01-01|      2014-12-31|                 N|2014|\n",
      "|    4|Bogotá, D.C.|35338|         1900-01-01|      2014-12-31|                 N|2014|\n",
      "+-----+------------+-----+-------------------+----------------+------------------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "DimAeropuertoHistoria\n",
      "columnas de la tabla : 25\n",
      "filas de la tabla : 860\n",
      "+------------+-----+---------------+--------------------+---------+-------+--------+----------+------------+--------------------+-----------+-------------+----------+-----+---------+----------+-----+----------+-------------+----------------+-------------------+----------------+------------------+----+-----+\n",
      "|IDAeropuerto|Sigla|           IATA|    NombreAeropuerto|Categoria|Latitud|Longitud| Municipio|Departamento|         Propietario| Explotador|LongitudPista|AnchoPista| PBMO|Elevacion|Resolucion|Clase|      Tipo|GCD_Municipio|GCD_Departamento|FechaInicioVigencia|FechaFinVigencia|VersionDelRegistro|Anio|IDPIB|\n",
      "+------------+-----+---------------+--------------------+---------+-------+--------+----------+------------+--------------------+-----------+-------------+----------+-----+---------+----------+-----+----------+-------------+----------------+-------------------+----------------+------------------+----+-----+\n",
      "|         587|  7GY|no-especificado|         LAS ACACIAS|Aeródromo| 5.0949|-73.9054|   Nemocón|Cundinamarca|JUAN BERNANDO SAN...|   EL MISMO|         1289|        14|10000|     8431|   439,000|   3A|   Público|        25486|              25|         2016-01-01|      2300-01-01|                 S|2016|   80|\n",
      "|         689|  9DI|no-especificado|          SAN FELIPE|Aeródromo|  1.915|-67.0776|San Felipe|     Guainía|         GOBERNACION|GOBERNACION|         3701|        59|25000|      312|   545,000|   1A| Aerocivil|        94883|              94|         2016-01-01|      2300-01-01|                 S|2016|   81|\n",
      "|         593|  7HE|no-especificado|GUACHARACAS (COLO...|Aeródromo| 4.7371|-74.8021|   Beltrán|Cundinamarca| EMPRESA GUACHARACAS|  CCA. LTDA|            3|         0| 3000|      797| 5,920,000|   1A| Aerocivil|        25086|              25|         2016-01-01|      2300-01-01|                 S|2016|   80|\n",
      "|         603|  7HQ|no-especificado|GENERAL ADELMO RU...|Aeródromo|   4.35|-74.7511|  Ricaurte|Cundinamarca|  EDUARDO A. VIVEROS|       ACAF|           69|        71|  500|      987|    46,000|   1A| Aerocivil|        25612|              25|         2016-01-01|      2300-01-01|                 S|2016|   80|\n",
      "|         750|  A01|no-especificado|        CAMPO ALEGRE|Aeródromo| 1.8653|-69.0101|   Inírida|     Guainía|         GOBERNACION|GOBERNACION|         2341|        50| 2000|      577| 1,333,000|   1A|Fumigación|        94001|              94|         2016-01-01|      2300-01-01|                 S|2016|   81|\n",
      "+------------+-----+---------------+--------------------+---------+-------+--------+----------+------------+--------------------+-----------+-------------+----------+-----+---------+----------+-----+----------+-------------+----------------+-------------------+----------------+------------------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "FactVuelos\n",
      "columnas de la tabla : 13\n",
      "filas de la tabla : 82386\n",
      "+-------+-----------+-------------+---------+--------+------------------+-------------------+------+---------+----------+-----------+----------+---+\n",
      "|IDFecha|IDTipoVuelo|IDTipoTrafico|IDEmpresa|IDEquipo|IDAeropuertoOrigen|IDAeropuertoDestino|Vuelos|Pasajeros|CargaBordo|TotalSillas|TotalCarga| ID|\n",
      "+-------+-----------+-------------+---------+--------+------------------+-------------------+------+---------+----------+-----------+----------+---+\n",
      "|     76|          3|            0|       50|      42|               828|                674|     1|        0|         0|          0|         0|  0|\n",
      "|     17|          3|            0|       13|      50|               183|                 97|     1|        2|       200|          2|       200|  1|\n",
      "|     44|          3|            0|       62|      52|               211|                 25|     1|        5|        40|          5|        40|  2|\n",
      "|     24|          3|            0|       69|      50|               183|                 53|     1|        2|         0|          2|         0|  3|\n",
      "|     38|          3|            0|        1|      50|               211|                 53|     1|        1|         0|          1|         0|  4|\n",
      "+-------+-----------+-------------+---------+--------+------------------+-------------------+------+---------+----------+-----------+----------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('DimFechaMes')\n",
    "table=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT * FROM DimFechaMes ) AS Temp_DimFechaMes''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load() \n",
    "print(\"columnas de la tabla : {0}\".format(len(table.columns)))\n",
    "print(\"filas de la tabla : {0}\".format(table.count()))\n",
    "print(table.show(5))\n",
    "print('DimTipoVuelo')\n",
    "table=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT * FROM DimTipoVuelo ) AS Temp_DimTipoVuelo''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load() \n",
    "print(\"columnas de la tabla : {0}\".format(len(table.columns)))\n",
    "print(\"filas de la tabla : {0}\".format(table.count()))\n",
    "print(table.show(5))\n",
    "print('DimTipo_Trafico')\n",
    "table=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT * FROM DimTipo_Trafico ) AS Temp_DimTipo_Trafico''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load() \n",
    "print(\"columnas de la tabla : {0}\".format(len(table.columns)))\n",
    "print(\"filas de la tabla : {0}\".format(table.count()))\n",
    "print(table.show(5))\n",
    "print('DimEmpresaTransportadora')\n",
    "table=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT * FROM DimEmpresaTransportadora ) AS Temp_DimTipo_Trafico''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load() \n",
    "print(\"columnas de la tabla : {0}\".format(len(table.columns)))\n",
    "print(\"filas de la tabla : {0}\".format(table.count()))\n",
    "print(table.show(5))\n",
    "print('DimTipo_Equipo')\n",
    "table=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT * FROM DimTipo_Equipo ) AS Temp_DimTipo_Equipo''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load() \n",
    "print(\"columnas de la tabla : {0}\".format(len(table.columns)))\n",
    "print(\"filas de la tabla : {0}\".format(table.count()))\n",
    "print(table.show(5))\n",
    "print('DimInformacionPIB')\n",
    "table=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT * FROM DimInformacionPIB ) AS Temp_DimInformacionPIB''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load() \n",
    "print(\"columnas de la tabla : {0}\".format(len(table.columns)))\n",
    "print(\"filas de la tabla : {0}\".format(table.count()))\n",
    "print(table.show(5))\n",
    "print('DimAeropuertoHistoria')\n",
    "table=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT * FROM DimAeropuertoHistoria ) AS Temp_DimAeropuertoHistoria''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load() \n",
    "print(\"columnas de la tabla : {0}\".format(len(table.columns)))\n",
    "print(\"filas de la tabla : {0}\".format(table.count()))\n",
    "print(table.show(5))\n",
    "print('FactVuelos')\n",
    "table=spark.read.format('jdbc')\\\n",
    "    .option('url', db_multidimensional_connection_string) \\\n",
    "    .option('dbtable', '''(SELECT * FROM FactVuelos ) AS Temp_DimFactVuelos''') \\\n",
    "    .option('user', user) \\\n",
    "    .option('password', passwd) \\\n",
    "    .option('driver', 'org.mariadb.jdbc.Driver') \\\n",
    "    .load() \n",
    "print(\"columnas de la tabla : {0}\".format(len(table.columns)))\n",
    "print(\"filas de la tabla : {0}\".format(table.count()))\n",
    "print(table.show(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67040d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
